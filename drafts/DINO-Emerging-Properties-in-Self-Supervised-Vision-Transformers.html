<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# fb: https://www.facebook.com/2008/fbml">
<head>
    <title>DINO: Improving supervised ViT with richer learning signal from self-supervision - MichaÅ‚ Chromiak's blog</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">


    <link href="https://mchromiak.github.io/static_files/img/favicon.jpg" rel="icon">

<link rel="canonical" href="https://mchromiak.github.io/drafts/DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers.html">

        <meta name="author" content="MichaÅ‚ Chromiak" />
        <meta name="keywords" content="Transformer,CV,Vision Transformer,ViT,Self-Supervision,SSL,k-NN" />
        <meta name="description" content="Self-DIstillation with NO labels (DINO) is a self-supervised method based on Vision Transformer (ViT) from Facebook AI with the ability to learn representation from unlabeled data. The architecture is able to learn automatically class-specific features, allowing the unsupervised object segmentation. The paper claims that the self-supervised methods adapted to ViT not only works very well, but one can also observe that the self-supervised ViT features contain explicit semantic segmentation information of an image, which is not that clear in case of supervised ViT, nor with convnets. The benefit of such observation is that such features are also very good k-NN classifiers. The performance results are reported to be highly dependent on two SSL approaches: the momentum teacher and multicrop training. In this blog post we will explain what DINO is all about." />

        <meta property="og:site_name" content="MichaÅ‚ Chromiak's blog" />
        <meta property="og:type" content="article"/>
        <meta property="og:title" content="DINO: Improving supervised ViT with richer learning signal from self-supervision"/>
        <meta property="og:url" content="https://mchromiak.github.io/drafts/DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers.html"/>
        <meta property="og:description" content="Self-DIstillation with NO labels (DINO) is a self-supervised method based on Vision Transformer (ViT) from Facebook AI with the ability to learn representation from unlabeled data. The architecture is able to learn automatically class-specific features, allowing the unsupervised object segmentation. The paper claims that the self-supervised methods adapted to ViT not only works very well, but one can also observe that the self-supervised ViT features contain explicit semantic segmentation information of an image, which is not that clear in case of supervised ViT, nor with convnets. The benefit of such observation is that such features are also very good k-NN classifiers. The performance results are reported to be highly dependent on two SSL approaches: the momentum teacher and multicrop training. In this blog post we will explain what DINO is all about."/>
            <meta property="og:image" content="https://mchromiak.github.io/articles/2021/May/03/img/Dino-Cover.png" />

        <meta property="article:published_time" content="2021-05-03" />
            <meta property="article:section" content="Computer Vision" />
            <meta property="article:tag" content="Transformer" />
            <meta property="article:tag" content="CV" />
            <meta property="article:tag" content="Vision Transformer" />
            <meta property="article:tag" content="ViT" />
            <meta property="article:tag" content="Self-Supervision" />
            <meta property="article:tag" content="SSL" />
            <meta property="article:tag" content="k-NN" />
            <meta property="article:author" content="MichaÅ‚ Chromiak" />


    <meta name="twitter:dnt" content="on">
    <meta name="twitter:card" content="summary_large_image">
        <meta name="twitter:site" content="@drChromiak">
        <meta name="twitter:creator" content="@drChromiak">
    <meta name="twitter:domain" content="https://mchromiak.github.io">
        <meta property="twitter:image"
              content="https://mchromiak.github.io/articles/2021/May/03/img/Dino-Cover.png"/>


    <!-- Bootstrap -->
        <link rel="stylesheet" href="https://mchromiak.github.io/theme/css/bootstrap.cerulean.min.css" type="text/css"/>
    <link href="https://mchromiak.github.io/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="https://mchromiak.github.io/theme/css/pygments/colorful.css" rel="stylesheet">
    <link rel="stylesheet" href="https://mchromiak.github.io/theme/css/style.css" type="text/css"/>
        <link href="https://mchromiak.github.io/static_files/css/custom.css" rel="stylesheet">

        <link href="https://mchromiak.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate"
              title="MichaÅ‚ Chromiak's blog ATOM Feed"/>



        <link href="https://mchromiak.github.io/feeds/computer-vision.atom.xml" type="application/atom+xml" rel="alternate"
              title="MichaÅ‚ Chromiak's blog Computer Vision ATOM Feed"/>

</head>
<body>

<div class="navbar navbar-default navbar-fixed-top" role="navigation">
	<div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="https://mchromiak.github.io/" class="navbar-brand">
<img class="img-responsive pull-left gap-right" src="https://mchromiak.github.io/static_files/img/sitelogo40.png" width=""/> MichaÅ‚ Chromiak's blog            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                         <li><a href="https://mchromiak.github.io/pages/about.html">
                             About
                          </a></li>
                         <li><a href="https://mchromiak.github.io/pages/categorisation.html">
                             Categorisation
                          </a></li>
                         <li><a href="https://mchromiak.github.io/pages/contact-detail.html">
                             Contact detail
                          </a></li>
                         <li><a href="https://mchromiak.github.io/pages/links.html">
                             Links
                          </a></li>
                         <li><a href="https://mchromiak.github.io/pages/resources.html">
                             Resources
                          </a></li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->
<!-- Banner -->
<!-- End Banner -->
<div class="container">
    <div class="row">
        <div class="col-sm-9">
            <ol class="breadcrumb">
                <li><a href="https://mchromiak.github.io" title="MichaÅ‚ Chromiak's blog"><i class="fa fa-home fa-lg"></i></a></li>
                <li><a href="https://mchromiak.github.io/category/computer-vision.html" title="Computer Vision">Computer Vision</a></li>
                <li class="active">DINO: Improving supervised ViT with richer learning signal from self-supervision</li>
            </ol>
    <section id="content">
        <article>
            <header class="page-header">
                <h1>
                    <a href="https://mchromiak.github.io/drafts/DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers.html"
                       rel="bookmark"
                       title="Permalink to DINO: Improving supervised ViT with richer learning signal from self-supervision">
                        DINO: Improving supervised ViT with richer learning signal from self-supervision
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2021-05-03T17:44:00+02:00"> Mon, 03 May 2021</time>
    </span>
          <span class="label label-default">Modified</span>
            <span class="modified">
                <i class="fa fa-calendar"></i><time datetime="2021-05-24T09:44:00+02:00"> Mon, 24 May 2021</time>
            </span>


            <span class="label label-default">By</span>
            <a href="https://mchromiak.github.io/author/michal-chromiak.html"><i class="fa fa-user"></i> MichaÅ‚ Chromiak</a>

        <span class="label label-default">Category</span>
        <a href="https://mchromiak.github.io/category/computer-vision.html">Computer Vision</a>


<span class="label label-default">Tags</span>
	<a href="https://mchromiak.github.io/tag/transformer.html">Transformer</a>
        /
	<a href="https://mchromiak.github.io/tag/cv.html">CV</a>
        /
	<a href="https://mchromiak.github.io/tag/vision-transformer.html">Vision Transformer</a>
        /
	<a href="https://mchromiak.github.io/tag/vit.html">ViT</a>
        /
	<a href="https://mchromiak.github.io/tag/self-supervision.html">Self-Supervision</a>
        /
	<a href="https://mchromiak.github.io/tag/ssl.html">SSL</a>
        /
	<a href="https://mchromiak.github.io/tag/k-nn.html">k-NN</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>
                <h4 id=the-dino-paper-explained>The "Dino" paper explained.<a class=headerlink href=#the-dino-paper-explained title="Permanent link">ðŸ”—</a></h4>
<p>In this article we will explain and discuss the paper:</p>
<p><strong><a href="https://arxiv.org/abs/2104.14294">"Emerging Properties in Self-Supervised Vision Transformers</a></strong>: ArXiv</p>
<h4 id=tldr>TL;DR<a class=headerlink href=#tldr title="Permanent link">ðŸ”—</a></h4>
<ul>
<li>For ViT with DINO, the smaller the patch (&lt;16) the better performance, and without additional parameters.</li>
<li>Conversely to convnets, or supervised ViT - image attention maps/features of SSL ViT (DINO), contain <strong>explicit</strong> image segmentation map.</li>
<li>SSL ViT features becomes a very good <em>k-NN</em> classifier - thanks to momentum encoder and multi-crop augmentation.</li>
<li>Dino directly predicts the output of a teacher network â€” built with a momentum encoder â€” by using a standard cross-entropy loss.</li>
<li>Comparing to remaining self-supervised learning (SSL)  the most important parts are:<ul>
<li>Usage of the <em>student-teacher</em> which is the self-distillation element, using momentum teacher with centering and sharpening.</li>
<li>Not using contrastive learning, batch norm, nor negative samples.</li>
</ul>
</li>
</ul>
<iframe width=896 height=504 src="https://www.youtube.com/embed/8I1RelnsgMw" title="YouTube video player" frameborder=0 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<h4 id=contribution-of-paper>Contribution of paper:<a class=headerlink href=#contribution-of-paper title="Permanent link">ðŸ”—</a></h4>
<ul>
<li>Investigate impact of self-supervised pretraining on ViT features with following results.<ul>
<li>Self-supervised ViT match and even outperforms convnets for poorly labeled data sets.</li>
<li>Self-supervised ViT's features contain explicit scene layout and object boundaries (self-attention modules of last block) (See Figure 1.). Such presence of segmentation masks is known to be shared across different SSL methods however, the <span class=math>\(k\)</span>-NN good performance originates from the decisions made for the DINO architecture - ie. momentum encoder and multi-crop augmentation.</li>
</ul>
</li>
<li>Smaller image patches (<span class=math>\(8\times8\)</span>) in ViT increase the quality of resulting features and improve performance (reduce running time but with larger usage of memory - lower throughput) without adding additional parameters.</li>
</ul>
<p align=center><img alt="Self-attention from a Vision Transformer with 8 Ã— 8 patches trained with no supervision \label{fig:dinofeatures}" src="https://mchromiak.github.io/drafts/img/dino-intro.png">
Figure 1. Object attention maps available explicitly from SSL ViT's features  (<a href="https://github.com/facebookresearch/dino">Source</a>).</p>
<hr>

<h3 id=intro>Intro<a class=headerlink href=#intro title="Permanent link">ðŸ”—</a></h3>
<p>Since 2017 when Transformers were first introduced (<a href="https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/">Transformer: Attention is all you need - Explained</a>), they have dominated research trends not only in NLP, but (as of 2020/21) also in computer vision tasks. The paper is based on most recent advancement with <a href="">Vision Transformer (ViT)</a> from Google AI, but there were more research also from Facebook AI such as the <a href=""><span class=math>\(DE\)</span>tection <span class=math>\(TR\)</span>ansformer (DETR)</a> or <a href=""><span class=math>\(D\)</span>ata-<span class=math>\(e\)</span>fficient <span class=math>\(i\)</span>mage <span class=math>\(T\)</span>ransformers (DeiT)</a> (the DeiT implementation is actually followed in the DINO).</p>
<p>The self-<strong>DI</strong>stillation with <strong>NO</strong> labels (DINO) approach to train ViT has been discussed in the paper with very extensive experiments and ablation study.</p>
<p>The initially prevalent role of Transformer based solutions in NLP has been recently adapted with success into the computer vision (CV) domain. However, until now, this evolution in many cases has assumed the supervised training strategy for vision tasks.</p>
<p>The supervised ViT architecture is an alternative to convnets in visual recognition tasks, however it is also more demanding in terms of:</p>
<ul>
<li>computation power</li>
<li>size of the training data, also with</li>
<li>class-specific, unique features properties not being clearly exhibited  </li>
</ul>
<p>The Transformers in vision applications has become an prominent alternative to convnets, but the question rise: <em>is this success due to the supervised nature of the pretraining phase</em>?</p>
<p>To answer this question, one approach is to couple ViTs with a self-supervised architecture, that would replace completely supervised processes in vision tasks, and that is what paper is actually exploring.</p>
<blockquote>
<p>Notes on Self-Supervised (no labels) Learning (SSL):</p>
<ul>
<li>In contrast to "completely" <em>unsupervised</em> setting, the SSL uses information from the dataset itself to construct pseudo-labels.</li>
<li>in SSL the supervision is induced by self-supervised tasks rather than preset prior knowledge.</li>
<li>Large-scale labeled data sets are not required for human learning as we learn spontaneously, thus the SSL has a great potential to replace the supervised learning in terms of <strong>representation learning</strong>. That is because in general, human learning is more a <strong>Few-Shot Learning</strong>, where we actually have a small amounts of annotated data.</li>
</ul>
</blockquote>
<h3 id=motivation>Motivation<a class=headerlink href=#motivation title="Permanent link">ðŸ”—</a></h3>
<p>Based on the fact that the self-supervised procedures in Transformer based architectures such as BERT (MLM) and GPT (language modeling) enrich learning signal comparing to the supervised variant of predicting single label per sentence. Same situation is with supervised image categorization where entire rich image visual information is reduced to single concept selected form set of categories of objects.   </p>
<h3 id=the-processing-strategy-of-the-algorithm>The processing strategy of the algorithm<a class=headerlink href=#the-processing-strategy-of-the-algorithm title="Permanent link">ðŸ”—</a></h3>
<p>The general techniques applied in DINO are the <strong>self-supervised learning (SSL), self-learning</strong> and <strong>knowledge distillation</strong>.</p>
<p>In terms of SSL, DINO is modeled based on metric-learning formulation called BYOL<sup id=sf-DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers-1-back><a href=#sf-DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers-1 class=simple-footnote title=" Grill et al. Bootstrap Your Own Latent - A New Approach to Self-Supervised Learning 2020">1</a></sup>. The approach train features by matching them to representations obtained with a <em>momentum encoder</em>. However, DINO operates with different similarity matching loss than BYOL. DINO is a SSL as a Mean Teacher<sup id=sf-DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers-2-back><a href=#sf-DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers-2 class=simple-footnote title="A method that averages model weights instead of label predictions. See paper: Tarvainen et al. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results">2</a></sup> self-distillation with no labels.</p>
<script src="https://vjs.zencdn.net/7.11.4/video.min.js"></script>
<!-- webm is 95% smaller than gif  -->
<video id=my-player class="video-js vjs-theme-sea vjs-big-play-centered" controls preload=auto autoplay loop="" muted="">
 <source src="../img/dino.webm" type="video/webm">
 <p class=vjs-no-js>
      To view this video please enable JavaScript, and consider upgrading to a web browser that
      <a href="https://videojs.com/html5-video-support/" target=_blank> supports HTML5 video</a>
    </p>
</video>

<!-- apng is smaller 50% than gif -->
<!-- ![DiNo]({attach}img/dino.apng) -->
<p align=center>Figure 2. DINO overview (<a href="https://github.com/facebookresearch/dino">Source</a>).</p>
<h4 id=what-is-a-knowledge-distillation>What is a knowledge distillation?<a class=headerlink href=#what-is-a-knowledge-distillation title="Permanent link">ðŸ”—</a></h4>
<p>In short, knowledge distillation is process of learning of the <em>student</em> model to match a <em>teacher</em> model predictions. This way distillation means to compress the knowledge into a smaller <em>student</em> model, that would be comparable to the <em>teacher</em> model. (See a paper from Hinton et al.<sup id=sf-DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers-3-back><a href=#sf-DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers-3 class=simple-footnote title="Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. preprint arXiv:1503.02531, 2015">3</a></sup>)</p>
<p>The <em>teacher</em> is usually a big model that is used to produce a smaller <em>student</em> model. Such a <strong>distilled</strong> <em>student</em> model is more effective than a adequate <em>student</em> model which would yield as a result of training from scratch.</p>
<h4 id=momentum-teacher>Momentum teacher<a class=headerlink href=#momentum-teacher title="Permanent link">ðŸ”—</a></h4>
<p>The DINO student and teacher have the same architecture where, the teacher is also built dynamically during training from the past iterations of the <em>student</em> network. This way distillation is applied as a self-supervised objective during training to the teacher's parameters by distilling from the <em>exponential moving average</em> (ema) of the student parameters.</p>
<h4 id=avoiding-collaps>Avoiding collaps<a class=headerlink href=#avoiding-collaps title="Permanent link">ðŸ”—</a></h4>
<p>As there is a lack of negative samples the main goal is to avoid <strong>collapse</strong>. collapse means that the network maps everything to the same representation, so every time it would return success as everything feed through it will be treated the same - all is the same. Collapse is therefore a trivial solution that one needs to avoid.
Some general approaches include contrastive loss, clustering constraints, predictor or batch normalizations however, DINO is only using  <em>centering</em> and <em>sharpening</em> of the <em>momentum teacher</em> outputs. Both solutions having opposite characteristics tends to balance each other effect at the same time assuring collapse avoidance.</p>
<h4 id=centering>Centering<a class=headerlink href=#centering title="Permanent link">ðŸ”—</a></h4>
<p>Centering prevents one dimension dominance while  paper</p>
<h4 id=sharpening>Sharpening<a class=headerlink href=#sharpening title="Permanent link">ðŸ”—</a></h4>
<h3 id=objective-or-goal-for-the-algorithm>Objective, or goal for the algorithm<a class=headerlink href=#objective-or-goal-for-the-algorithm title="Permanent link">ðŸ”—</a></h3>
<h3 id=metaphors-or-analogies-to-other-architectures-describing-the-behavior-of-the-algorithm>Metaphors, or analogies to other architectures describing the behavior of the algorithm<a class=headerlink href=#metaphors-or-analogies-to-other-architectures-describing-the-behavior-of-the-algorithm title="Permanent link">ðŸ”—</a></h3>
<h3 id=heuristics-or-rules-of-thumb>Heuristics or rules of thumb<a class=headerlink href=#heuristics-or-rules-of-thumb title="Permanent link">ðŸ”—</a></h3>
<h3 id=is-dino-a-gan>Is DINO a GAN?<a class=headerlink href=#is-dino-a-gan title="Permanent link">ðŸ”—</a></h3>
<h3 id=what-classes-of-problem-is-the-algorithm-well-suited>What classes of problem is the algorithm well suited?<a class=headerlink href=#what-classes-of-problem-is-the-algorithm-well-suited title="Permanent link">ðŸ”—</a></h3>
<h3 id=common-benchmark-or-example-datasets-used-to-demonstrate-the-algorithm>Common benchmark or example datasets used to demonstrate the algorithm<a class=headerlink href=#common-benchmark-or-example-datasets-used-to-demonstrate-the-algorithm title="Permanent link">ðŸ”—</a></h3>
<h3 id=useful-resources-for-learning-more-about-the-algorithm>Useful resources for learning more about the algorithm:<a class=headerlink href=#useful-resources-for-learning-more-about-the-algorithm title="Permanent link">ðŸ”—</a></h3>
<ul>
<li><a href="https://ai.facebook.com/blog/dino-paws-computer-vision-with-self-supervised-transformers-and-10x-more-efficient-training">Facebook AI blog post</a></li>
<li><a href="https://github.com/facebookresearch/dino">GitHub with PyTorch implementation</a></li>
<li><a href="https://www.arxiv-vanity.com/papers/2104.14294/">ArXiv-Vanity Web version of ArXiv Paper</a></li>
<li><a href="https://arxiv.org/abs/2104.14294">ArXiv Paper</a></li>
<li><a href="https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/">Facebook blog post from Yann LeCun: "Self-supervised learning: The dark matter of intelligence"</a></li>
</ul>
<h3 id=footnotes>Footnotes:<a class=headerlink href=#footnotes title="Permanent link">ðŸ”—</a></h3>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script><ol class=simple-footnotes><li id=sf-DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers-1> Grill et al. <a href="https://arxiv.org/abs/2006.07733">Bootstrap Your Own Latent - A New Approach to Self-Supervised Learning</a> 2020 <a href=#sf-DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers-1-back class=simple-footnote-back>â†©</a></li><li id=sf-DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers-2>A method that averages model weights instead of label predictions. See paper: Tarvainen et al. <a href="https://arxiv.org/abs/1703.01780">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</a> <a href=#sf-DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers-2-back class=simple-footnote-back>â†©</a></li><li id=sf-DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers-3>Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. <a href="https://arxiv.org/abs/1503.02531">Distilling the knowledge in a neural network.</a> preprint arXiv:1503.02531, 2015 <a href=#sf-DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers-3-back class=simple-footnote-back>â†©</a></li></ol>
            </div>
            <!-- /.entry-content -->
<section class="well" id="related-posts">
    <h4>Related Posts:</h4>
    <ul>
        <li><a href="https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/">The Transformer â€“ Attention is all you need.</a></li>
    </ul>
</section>
    <hr />
    <!-- AddThis Button BEGIN -->
    <div class="addthis_toolbox addthis_default_style">
            <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
            <a class="addthis_button_tweet"></a>
            <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    </div>
    <!-- AddThis Button END -->
    <hr/>
    <section class="comments" id="comments">
        <h2>Comments</h2>

        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'mchromiak'; // required: replace example with your forum shortname

                var disqus_url = 'https://mchromiak.github.io/drafts/DINO-Emerging-Properties-in-Self-Supervised-Vision-Transformers.html';

            var disqus_config = function () {
                this.language = "en";
            };

            /* * * DON'T EDIT BELOW THIS LINE * * */
            (function () {
                var dsq = document.createElement('script');
                dsq.type = 'text/javascript';
                dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by
            Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    </section>
        </article>
    </section>

        </div>
        <div class="col-sm-3" id="sidebar">
            <aside>
<div id="aboutme">
        <p>
            <img width="100%" class="img-thumbnail" src="https://mchromiak.github.io/static_files/img/me.png"/>
        </p>
    <p>
      <strong>About MichaÅ‚ Chromiak</strong><br/>
         PhD in Computer Science by Polish Academy of Sciences (PAS). Focus research on understanding chaos of data. Deeply understanding the phenomena makes it easy, but first you need to learn. Holds two MScs, in Mathematics and in Computer Science.
    </p>
</div><!-- Sidebar -->
<section class="well well-sm">
  <ul class="list-group list-group-flush">

<!-- Sidebar/Social -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
  <ul class="list-group" id="social">
    <li class="list-group-item"><a href="https://www.linkedin.com/in/michal-chromiak"><i class="fa fa-linkedin-square fa-lg"></i> LinkedIn</a></li>
    <li class="list-group-item"><a href="https://github.com/MichalChromiak"><i class="fa fa-github-square fa-lg"></i> GitHub</a></li>
    <li class="list-group-item"><a href="https://twitter.com/drChromiak"><i class="fa fa-twitter-square fa-lg"></i> Twitter</a></li>
    <li class="list-group-item"><a href="https://www.researchgate.net/profile/Michal_Chromiak"><i class="fa fa-researchgate-square fa-lg"></i> ResearchGate</a></li>
    <li class="list-group-item"><a href="https://scholar.google.pl/citations?user=UeOad3YAAAAJ&hl=en"><i class="fa fa-google-scholar-square fa-lg"></i> Google Scholar</a></li>
    <li class="list-group-item"><a href="localhost:8000/feeds/all.rss"><i class="fa fa-rss-square fa-lg"></i> RSS</a></li>
  </ul>
</li>
<!-- End Sidebar/Social -->

<!-- Sidebar/Recent Posts -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Recent Posts</span></h4>
  <ul class="list-group" id="recentposts">
    <li class="list-group-item"><a href="https://mchromiak.github.io/articles/2021/Jun/01/Decision-Transformer-Reinforcement-Learning-via-Sequence-Modeling-RL-as-sequence/">Decision Transformer: Unifying sequence modelling and model-free, offline RL</a></li>
    <li class="list-group-item"><a href="https://mchromiak.github.io/articles/2021/May/06/MLP-Mixer/">MLP-Mixer: MLP is all you need... again? ...</a></li>
    <li class="list-group-item"><a href="https://mchromiak.github.io/articles/2021/May/01/RL-Primer/">RL Primer</a></li>
  </ul>
</li>
<!-- End Sidebar/Recent Posts -->

<!-- Sidebar/Categories -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Categories</span></h4>
  <ul class="list-group" id="categories">
    <li class="list-group-item">
      <a href="https://mchromiak.github.io/category/applications.html"><i class="fa fa-folder-open fa-lg"></i>Applications</a>
    </li>
    <li class="list-group-item">
      <a href="https://mchromiak.github.io/category/computer-vision.html"><i class="fa fa-folder-open fa-lg"></i>Computer Vision</a>
    </li>
    <li class="list-group-item">
      <a href="https://mchromiak.github.io/category/ml-dojo.html"><i class="fa fa-folder-open fa-lg"></i>ML Dojo</a>
    </li>
    <li class="list-group-item">
      <a href="https://mchromiak.github.io/category/reinforcement-learning.html"><i class="fa fa-folder-open fa-lg"></i>Reinforcement learning</a>
    </li>
    <li class="list-group-item">
      <a href="https://mchromiak.github.io/category/sequence-models.html"><i class="fa fa-folder-open fa-lg"></i>Sequence Models</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Categories -->

<!-- Sidebar/Tag Cloud -->
<li class="list-group-item">
  <a href="https://mchromiak.github.io/"><h4><i class="fa fa-tags fa-lg"></i><span class="icon-label">Tags</span></h4></a>
  <ul class="list-group list-inline tagcloud" id="tags">
    <li class="list-group-item tag-4">
      <a href="https://mchromiak.github.io/tag/application.html">application</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://mchromiak.github.io/tag/attention-model.html">Attention model</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://mchromiak.github.io/tag/basics.html">basics</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://mchromiak.github.io/tag/bert.html">BERT</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://mchromiak.github.io/tag/cv.html">CV</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://mchromiak.github.io/tag/elmo.html">ELMo</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://mchromiak.github.io/tag/ernie-10.html">ERNIE 1.0</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://mchromiak.github.io/tag/language-model.html">language model</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://mchromiak.github.io/tag/machine-translation.html">Machine translation</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://mchromiak.github.io/tag/markov-decision-process.html">Markov Decision Process</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://mchromiak.github.io/tag/mdp.html">MDP</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://mchromiak.github.io/tag/mlp.html">MLP</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://mchromiak.github.io/tag/ngram.html">ngram</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="https://mchromiak.github.io/tag/nlp.html">NLP</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://mchromiak.github.io/tag/nmt.html">NMT</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://mchromiak.github.io/tag/openai-gpt.html">OpenAI GPT</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://mchromiak.github.io/tag/patternrecognition.html">PatternRecognition</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://mchromiak.github.io/tag/perplexity.html">perplexity</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://mchromiak.github.io/tag/reinforcement-learning.html">Reinforcement Learning</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://mchromiak.github.io/tag/rl.html">RL</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://mchromiak.github.io/tag/seq2seq.html">seq2seq</a>
    </li>
    <li class="list-group-item tag-2">
      <a href="https://mchromiak.github.io/tag/sequence-transduction.html">Sequence transduction</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://mchromiak.github.io/tag/smoothing.html">smoothing</a>
    </li>
    <li class="list-group-item tag-1">
      <a href="https://mchromiak.github.io/tag/transformer.html">Transformer</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://mchromiak.github.io/tag/vit.html">ViT</a>
    </li>
    <li class="list-group-item tag-4">
      <a href="https://mchromiak.github.io/tag/xlnet.html">XLNet</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Tag Cloud -->

<!-- Sidebar/Links -->
<li class="list-group-item">
  <h4><i class="fa fa-external-link-square fa-lg"></i><span class="icon-label">Links</span></h4>
  <ul class="list-group" id="links">
    <li class="list-group-item">
      <a href="http://www.iclr.cc" target="_blank">ICLR Conf</a>
    </li>
    <li class="list-group-item">
      <a href="http://icml.cc" target="_blank">ICML Conf</a>
    </li>
    <li class="list-group-item">
      <a href="https://nips.cc/" target="_blank">NIPS Conf</a>
    </li>
    <li class="list-group-item">
      <a href="http://aifrontiers.com/" target="_blank">AI Frontiers</a>
    </li>
    <li class="list-group-item">
      <a href="https://developers.google.com/machine-learning/glossary/" target="_blank">ML Glossary</a>
    </li>
    <li class="list-group-item">
      <a href="https://deepdreamgenerator.com/" target="_blank">Deep Dream Generator</a>
    </li>
    <li class="list-group-item">
      <a href="https://deepart.io/" target="_blank">DeepArt Generator</a>
    </li>
    <li class="list-group-item">
      <a href="https://stanfordmlgroup.github.io/" target="_blank">Stanford ML Group Andrew Ng</a>
    </li>
    <li class="list-group-item">
      <a href="https://ai-on.org/" target="_blank">AIâ€¢ON open ML collaboration</a>
    </li>
    <li class="list-group-item">
      <a href="http://java-hive.blogspot.com/" target="_blank">My old blog on Java an SE</a>
    </li>
    <li class="list-group-item">
      <a href="http://karpathy.github.io/2016/09/07/phd/" target="_blank">PhD</a>
    </li>
    <li class="list-group-item">
      <a href="http://alt.qcri.org/semeval2017/" target="_blank">SemEval2017</a>
    </li>
    <li class="list-group-item">
      <a href="https://medium.freecodecamp.org/450-free-online-programming-computer-science-courses-you-can-start-in-september-59712e77635c" target="_blank">Free CS courses</a>
    </li>
  </ul>
</li>
<!-- End Sidebar/Links -->

<!-- Sidebar/Archive -->
<li class="list-group-item">
  <h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Archive</span></h4>
  <ul class="list-group" id="archive">
        <li class="list-group-item">
          <a href="https://mchromiak.github.io/archive/2021/Jun/index.html"><i class="fa fa-calendar fa-lg"></i>June 2021 (1)
          </a>
        </li>
        <li class="list-group-item">
          <a href="https://mchromiak.github.io/archive/2021/May/index.html"><i class="fa fa-calendar fa-lg"></i>May 2021 (2)
          </a>
        </li>
        <li class="list-group-item">
          <a href="https://mchromiak.github.io/archive/2019/Jul/index.html"><i class="fa fa-calendar fa-lg"></i>July 2019 (1)
          </a>
        </li>
        <li class="list-group-item">
          <a href="https://mchromiak.github.io/archive/2017/Nov/index.html"><i class="fa fa-calendar fa-lg"></i>November 2017 (1)
          </a>
        </li>
        <li class="list-group-item">
          <a href="https://mchromiak.github.io/archive/2017/Sep/index.html"><i class="fa fa-calendar fa-lg"></i>September 2017 (2)
          </a>
        </li>
        <li class="list-group-item">
          <a href="https://mchromiak.github.io/archive/2017/Aug/index.html"><i class="fa fa-calendar fa-lg"></i>August 2017 (1)
          </a>
        </li>
  </ul>
</li>
<!-- End Sidebar/Archive -->
  </ul>
</section>
<!-- End Sidebar -->            </aside>
        </div>
    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2021 MichaÅ‚ Chromiak
            &middot; Powered by <a href="https://github.com/getpelican/pelican-themes/tree/master/pelican-bootstrap3" target="_blank">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank">Bootstrap</a>                <p><small>  <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en"><img alt="Creative Commons License" style="border-width:0" src="//i.creativecommons.org/l/by-sa/4.0/80x15.png" /></a>
    Content
  licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">Creative Commons Attribution-ShareAlike 4.0 International License</a>, except where indicated otherwise.
</small></p>
         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="https://mchromiak.github.io/theme/js/jquery.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="https://mchromiak.github.io/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="https://mchromiak.github.io/theme/js/respond.min.js"></script>

    <script src="https://mchromiak.github.io/static_files/js/custom.js"></script>

    <script src="https://mchromiak.github.io/theme/js/bodypadding.js"></script>
    <!-- Disqus -->
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'mchromiak'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script');
            s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <!-- End Disqus Code -->
    <!-- Google Analytics Universal -->
    <script type="text/javascript">
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-108394162-1', 'auto');
        ga('send', 'pageview');
    </script>
    <!-- End Google Analytics Universal Code -->


        <script type="text/javascript">var addthis_config = {"data_track_addressbar": true};</script>
    <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-59ea3c17b283c631"></script>
    <script src="https://mchromiak.github.io/static_files/js/article.js"></script>
</body>
</html>